{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrator Agent\n",
    "\n",
    "This notebook orchestrates the entire ASRA workflow by coordinating the different agents and managing the research process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from typing import Dict, List\n",
    "import json\n",
    "from datetime import datetime\n",
    "from utils.config import setup_logging, OUTPUTS_DIR\n",
    "from utils.helpers import save_json\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup logging\n",
    "logger = setup_logging('orchestrator')\n",
    "\n",
    "class ResearchOrchestrator:\n",
    "    def __init__(self):\n",
    "        self.agents_dir = Path.cwd()\n",
    "        self.workflow_status = {}\n",
    "        \n",
    "    def execute_notebook(self, notebook_path: Path) -> Dict:\n",
    "        \"\"\"Execute a Jupyter notebook and return its output.\"\"\"\n",
    "        try:\n",
    "            # Load notebook\n",
    "            with open(notebook_path) as f:\n",
    "                nb = nbformat.read(f, as_version=4)\n",
    "            \n",
    "            # Execute notebook\n",
    "            ep = ExecutePreprocessor(timeout=600, kernel_name='python3')\n",
    "            ep.preprocess(nb, {'metadata': {'path': str(notebook_path.parent)}})\n",
    "            \n",
    "            return {\n",
    "                'status': 'success',\n",
    "                'notebook': notebook_path.name\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error executing notebook {notebook_path}: {str(e)}\")\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'notebook': notebook_path.name,\n",
    "                'error': str(e),\n",
    "                'traceback': traceback.format_exc()\n",
    "            }\n",
    "    \n",
    "    def run_research_workflow(self) -> Dict:\n",
    "        \"\"\"Execute the complete research workflow.\"\"\"\n",
    "        workflow_steps = [\n",
    "            ('literature_review.ipynb', 'Literature Review'),\n",
    "            ('hypothesis_generator.ipynb', 'Hypothesis Generation'),\n",
    "            ('data_analyzer.ipynb', 'Data Analysis'),\n",
    "            ('visualizer.ipynb', 'Visualization')\n",
    "        ]\n",
    "        \n",
    "        results = {}\n",
    "        for notebook, step_name in workflow_steps:\n",
    "            logger.info(f'Starting {step_name}')\n",
    "            \n",
    "            # Execute notebook\n",
    "            notebook_path = self.agents_dir / notebook\n",
    "            step_result = self.execute_notebook(notebook_path)\n",
    "            \n",
    "            # Store results\n",
    "            results[step_name] = step_result\n",
    "            \n",
    "            # Check for errors\n",
    "            if step_result['status'] == 'error':\n",
    "                logger.error(f'Workflow failed at {step_name}')\n",
    "                break\n",
    "            \n",
    "            logger.info(f'Completed {step_name}')\n",
    "        \n",
    "        # Save workflow results\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_path = OUTPUTS_DIR / f'workflow_results_{timestamp}.json'\n",
    "        save_json(results, output_path)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def run_research_pipeline() -> None:\n",
    "    \"\"\"Run the complete research pipeline.\"\"\"\n",
    "    logger.info('Starting research pipeline')\n",
    "    \n",
    "    try:\n",
    "        # Initialize orchestrator\n",
    "        orchestrator = ResearchOrchestrator()\n",
    "        \n",
    "        # Run workflow\n",
    "        results = orchestrator.run_research_workflow()\n",
    "        \n",
    "        # Check overall status\n",
    "        success = all(step['status'] == 'success' for step in results.values())\n",
    "        \n",
    "        if success:\n",
    "            logger.info('Research pipeline completed successfully')\n",
    "        else:\n",
    "            logger.error('Research pipeline completed with errors')\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f'Error in research pipeline: {str(e)}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Run pipeline\n",
    "    results = run_research_pipeline()\n",
    "    \n",
    "    # Print summary\n",
    "    if results:\n",
    "        print(\"\\nWorkflow Summary:\")\n",
    "        for step, result in results.items():\n",
    "            status = \"✓\" if result['status'] == 'success' else \"✗\"\n",
    "            print(f\"{status} {step}\")\n",
    "            if result['status'] == 'error':\n",
    "                print(f\"  Error: {result['error']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
